import streamlit as st
import pandas as pd
import os
import re
from datetime import datetime
import time

st.set_page_config(page_title="Time-MoE AD Monitor", layout="wide")

st.title("ğŸ“ Time-MoE 50M Anomaly Detection ì‹¤ì‹œê°„ ë¸Œë¦¬í•‘")

# ì‚¬ì´ë“œë°”: ì‹œìŠ¤í…œ ìƒíƒœ
st.sidebar.header("ğŸ–¥ï¸ System Status")
try:
    gpu_info = os.popen('nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits').read()
    if gpu_info:
        util, mem_used, mem_total = gpu_info.strip().split(',')
        st.sidebar.metric("GPU Utilization", f"{util}%")
        st.sidebar.progress(int(util)/100)
        st.sidebar.metric("VRAM Usage", f"{mem_used}MB / {mem_total}MB")
except:
    st.sidebar.error("Could not fetch GPU info.")

# 1. ì²´í¬í¬ì¸íŠ¸ í˜„í™©
st.header("ğŸ“‚ Saved Checkpoints")
ckpt_dirs = ["Time-MoE/checkpoints", "Time-MoE/checkpoints_backup_1768974147"]

# ë¡œê·¸ ë°ì´í„° ë¨¼ì € íŒŒì‹± (ì²´í¬í¬ì¸íŠ¸ì™€ ë§¤ì¹­í•˜ê¸° ìœ„í•¨)
log_path = "Time-MoE/run_base.log"
log_df = pd.DataFrame()
if os.path.exists(log_path):
    with open(log_path, 'r') as f:
        log_content = f.read()
    pattern = r"\|\s+(\d+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|"
    matches = re.findall(pattern, log_content)
    if matches:
        log_df = pd.DataFrame(matches, columns=['Step', 'Loss', 'Gating', 'F1-L1', 'F1-L2', 'F1-Total'])
        for col in log_df.columns:
            log_df[col] = pd.to_numeric(log_df[col])

if os.path.exists(log_path):
    with open(log_path, 'r') as f:
        log_content = f.read()
    pattern = r"\|\s+(\d+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|\s+([\d\.]+)\s+\|"
    matches = re.findall(pattern, log_content)
    if matches:
        log_df = pd.DataFrame(matches, columns=['Step', 'Loss', 'Gating', 'F1-L1', 'F1-L2', 'F1-Total'])
        for col in log_df.columns:
            log_df[col] = pd.to_numeric(log_df[col])

ckpt_list = []
for ckpt_dir in ckpt_dirs:
    if os.path.exists(ckpt_dir):
        ckpts = [d for d in os.listdir(ckpt_dir) if os.path.isdir(os.path.join(ckpt_dir, d))]
        ckpts.sort(key=lambda x: os.path.getmtime(os.path.join(ckpt_dir, x)), reverse=True)
        
        for c in ckpts:
            path = os.path.join(ckpt_dir, c)
            mtime = datetime.fromtimestamp(os.path.getmtime(path)).strftime('%Y-%m-%d %H:%M:%S')
            try:
                size = os.popen(f"du -sh {path}").read().split()[0]
            except:
                size = "N/A"
            
            # í´ë”ëª…ì—ì„œ ìŠ¤í… ë²ˆí˜¸ ì¶”ì¶œ
            step_match = re.search(r'step-(\d+)|checkpoint-(\d+)', c)
            if step_match:
                step_val = int(step_match.group(1)) if step_match.group(1) else int(step_match.group(2))
            else:
                step_val = -1
            
            # ë¡œê·¸ ë°ì´í„°ì—ì„œ í•´ë‹¹ ìŠ¤í…ì˜ Loss ì°¾ê¸°
            ckpt_loss = -1.0 # ê¸°ë³¸ê°’ float
            if step_val != -1 and not log_df.empty:
                matched_row = log_df[log_df['Step'] == step_val]
                if not matched_row.empty:
                    try:
                        ckpt_loss = float(matched_row.iloc[0]['Loss'])
                    except:
                        ckpt_loss = -1.0
            
            # ì†ŒìŠ¤ êµ¬ë¶„ (Current vs Backup)
            source_label = "Current" if "backup" not in ckpt_dir else "Backup"
            
            ckpt_list.append({
                "Source": source_label,
                "Checkpoint": c, 
                "Step": step_val, 
                "Loss": ckpt_loss,
                "Saved At": mtime, 
                "Size": size,
                "Path": path # ë‚´ë¶€ ë¡œì§ìš© ì „ì²´ ê²½ë¡œ
            })

if ckpt_list:
    st.table(pd.DataFrame(ckpt_list).drop(columns=['Path']))
else:
    st.info("No checkpoint folders found yet.")

# 2. ì—ì´ì „íŠ¸ ë¦¬í¬íŠ¸ ë¶„ì„ (F1 Score ì¶”ì´)
st.header("ğŸ“Š Agent Performance Report")
if not log_df.empty:
    df = log_df
    # Summary Metrics
    latest = df.iloc[-1]
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Current Step", int(latest['Step']))
    m2.metric("Latest Loss", f"{latest['Loss']:.4f}")
    m3.metric("F1-Total", f"{latest['F1-Total']:.4f}")
    m4.metric("Gating Balance", f"{latest['Gating']:.4f}")

    # Charts
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“‰ Loss Convergence")
        st.line_chart(df.set_index('Step')['Loss'])
    with col2:
        st.subheader("ğŸ“ˆ F1 Score Progress")
        st.line_chart(df.set_index('Step')[['F1-L1', 'F1-L2', 'F1-Total']])
        
    st.subheader("ğŸ“‹ Historical Agent Reports")
    # use_container_width deprecated -> width
    st.dataframe(df.sort_values('Step', ascending=False))
else:
    if os.path.exists(log_path):
        st.info("Agent reports (Step | Loss | F1...) not found in log yet. Waiting for first 3h evaluation...")
    else:
        st.error(f"Log file '{log_path}' not found. Training might not have started correctly.")

# 3. Deep Diagnosis (ì‹¬ì¸µ ë¶„ì„)
st.divider()
st.header("ğŸ”¬ Deep Diagnosis")

if ckpt_list:
    # ckpt_listë¥¼ Step ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    ckpt_list.sort(key=lambda x: x['Step'], reverse=True)
    
    # Path ì •ë³´ëŠ” selectboxì˜ keyë¡œ í™œìš©í•˜ê¸° ìœ„í•´ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¦
    # í˜•ì‹: "Source/CheckpointName (Step: X)"
    ckpt_options = {f"{item['Source']}/{item['Checkpoint']} (Step: {item['Step']})": item['Path'] for item in ckpt_list}
    
    selected_option = st.selectbox("Select Checkpoint for Analysis", list(ckpt_options.keys()))
    selected_path = ckpt_options[selected_option]
    selected_ckpt_name = os.path.basename(selected_path) # ë¶„ì„ ê²°ê³¼ í´ë”ëª…ìœ¼ë¡œ ì‚¬ìš©
    
    if st.button("ğŸš€ Run Deep Analysis (Warning: Consumes VRAM)"):
        with st.spinner("Analyzing... This may take 1-2 minutes..."):
            import subprocess
            output_dir = os.path.join("Time-MoE/analysis_results", selected_ckpt_name)
            
            st.warning("âš ï¸ Running analysis while training is active may cause OOM. Pause training if needed.")
            
            cmd = ["python3", "Time-MoE/run_deep_analysis.py", selected_path, output_dir]
            process = subprocess.run(cmd, capture_output=True, text=True)
            
            if process.returncode == 0:
                st.success("Analysis Completed!")
            else:
                st.error(f"Analysis Failed:\n{process.stderr}")

    # Display Results
    # ë¶„ì„ ê²°ê³¼ í´ë”ëª…ì€ ì²´í¬í¬ì¸íŠ¸ í´ë”ëª…ê³¼ ë™ì¼í•˜ê²Œ ê°€ì •
    output_dir = os.path.join("Time-MoE/analysis_results", selected_ckpt_name) if 'selected_ckpt_name' in locals() else None
    
    if output_dir and os.path.isdir(output_dir):
        images = [f for f in os.listdir(output_dir) if f.endswith('.png')]
        if images:
            st.subheader(f"Results for {selected_ckpt_name}")
            tab1, tab2, tab3, tab4 = st.tabs(["Score Dist", "Expert Heatmap", "FFT Spectrum", "PR Curve"])
            
            def show_plot(filename):
                full_path = os.path.join(output_dir, filename)
                if os.path.exists(full_path):
                    st.image(full_path, caption=filename)
                else:
                    st.warning(f"File {filename} not found.")

            with tab1: show_plot("1_score_distribution.png")
            with tab2: show_plot("2_expert_heatmap.png")
            with tab3: show_plot("3_fft_spectrum.png")
            with tab4: show_plot("5_pr_curve.png")
        else:
            st.info("Analysis folder exists but contains no images. Run analysis to generate plots.")
else:
    st.info("No checkpoints available for analysis.")

# Auto-refresh logic
st.divider()
st.caption(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}. Auto-refreshing every 60s.")
time.sleep(60)
st.rerun()
